---
layout: archive
title: "Research"
permalink: /current_research/
author_profile: true
---
\n
\n

How do scientists cope with experimental failures?
======
[Download Paper](/files/cod_working_paper.pdf)
How do scientists address failures when producing experimental data? While the social dynamics of failures at the epistemological level – such as questioning or defending theories upon failures – are well examined, failures “at the bench” in day-to-day laboratory work have been less understood. Moreover, failures from the bench often precede the aforementioned epistemological interplays involving evaluation and readjustment of theories and hypotheses. We explore these “low-level data generation” processes based on ethnographic observations from material science labs to understand the work of scientists addressing data production. Analyzing these failures provides a strategic site for the sociology of science as it not only addresses potential bottlenecks in production of science but also reveals problem-solving processes, skills, and the interplay between epistemological and material dimensions and the degree to which the knowledge is situated. We find that scientists’ situated knowledge of empirical data production work is essential in identifying and searching for causes and solutions to failures. Secondly, due to the situated nature of data production, we find that necessary information for addressing these failures is primarily communicated and shared among lab members who are engaged in similar tasks. Our last main finding reveals an interesting aspect of scientists’ search behavior. We find that scientists tend to internalize failures initially, blaming themselves, before attributing these failures to external factors. Based on our in-depth observations and conceptualizations, we present a model named the “Cycle of Doubt,” which generalizes the failure-coping process. We provide a detailed discussion of the theoretical and practical implications of our findings. 
\n

Gender and Attrition in the Changing Organization of Scientific Work
======
[Download Paper](/files/gender_working_paper.pdf)
Despite longstanding concerns about the under-representation of women in science, few studies have approached this issue from the perspective of the changing organization of work in science. Past studies have documented a trend toward increased bureaucratization of scientific work, marked by the growing number of scientists specialized in supporting roles. Using data on publishing careers of scientists from 1951 to 2012 from selected natural and social science fields, we show that these “supporting” career-type scientists have been traditionally associated with women. While we find that the gender difference in career types has converged over the past few decades, this convergence has been largely driven by an increasing share of male scientists taking on supporting roles. We also find that historical gender inequality in career attrition in science is largely attributable to women traditionally occupying “supporting” roles, which suggests that examining work organization is crucial for understanding gender inequality in science. Lastly, using survival analysis, we find that both female “lead” and “supporting” career types face higher attrition rates than their male counterparts. Meanwhile, we find that “lead” career types yield fewer advantages for women compared to men in natural sciences, whereas “supporting” career types are particularly disadvantageous for women in social sciences. Our findings provide science policymakers with insights necessary to tailor support for women scientists by considering the nuances of their career types. 
\n

On the Shoulders of Fallen Giants: What do references to retracted research tell us about citation behaviors?
======
[Download Paper](/files/fallen_giant_working_paper.pdf)
Citations are increasingly being used to evaluate institutional and individual performance, suggesting a need for rigorous research to understand what behaviors citations are reflecting and what these behaviors mean for the institution of science. To overcome challenges in accurately representing the citation generation process, we use post-retraction citations to test competing theories under two different citation search processes, empirically testing predictions on the spread of retracted references. We find that retracted papers are continuously cited after the retraction, and that these citations are more likely to come from audiences likely to be unfamiliar with the field of the retracted paper. In addition, we find this association to be much stronger among those citing high-status journals, consistent with the behavior of scientists relying on heuristic search instead of engaged search process. While the current policy debate on misinformation in science emphasizes increasing the visibility of retraction labels to discourage the use of such publications, we argue that institutional-level interventions may be more effective, as such interventions are more consistent with the heuristic citation process. As such citation behavior may not be limited to the case of post-retraction citations, we discuss the implications for current science studies as well as science policy.
